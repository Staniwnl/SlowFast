{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DEMO.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOELFxiow/gO9otDHCdtN2C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6QiiNvF6_jhr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644259489,"user_tz":-480,"elapsed":22373,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"5ad45edd-f4c4-4b58-8c23-ef4aff7beb5d"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XHEz3ngmAodB"},"source":["import os\n","os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/SlowFast\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QaYBCvu9BINK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644269049,"user_tz":-480,"elapsed":903,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"1e6a8fca-c3a7-44b9-862e-b9d7a4259a38"},"source":["cd slowfast"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/SlowFast/slowfast\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C__Lj5ogBMx9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644409923,"user_tz":-480,"elapsed":139554,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"b343723f-1cf2-4621-d927-90087397786b"},"source":["pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.5.1+cu101\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n","\u001b[K     |████████████████████████████████| 704.4MB 24kB/s \n","\u001b[?25hCollecting torchvision==0.6.1+cu101\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n","\u001b[K     |████████████████████████████████| 6.6MB 117kB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.19.4)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n","Installing collected packages: torch, torchvision\n","  Found existing installation: torch 1.7.0+cu101\n","    Uninstalling torch-1.7.0+cu101:\n","      Successfully uninstalled torch-1.7.0+cu101\n","  Found existing installation: torchvision 0.8.1+cu101\n","    Uninstalling torchvision-0.8.1+cu101:\n","      Successfully uninstalled torchvision-0.8.1+cu101\n","Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4UPmFIJiHLKw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644419957,"user_tz":-480,"elapsed":8986,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"904a5a0f-51aa-4ecf-f2e2-a16f1fd5708e"},"source":["pip install 'git+https://github.com/facebookresearch/fvcore'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/facebookresearch/fvcore\n","  Cloning https://github.com/facebookresearch/fvcore to /tmp/pip-req-build-mzrariwv\n","  Running command git clone -q https://github.com/facebookresearch/fvcore /tmp/pip-req-build-mzrariwv\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (1.19.4)\n","Collecting yacs>=0.1.6\n","  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n","Collecting pyyaml>=5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n","\u001b[K     |████████████████████████████████| 276kB 15.0MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (4.41.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (1.1.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (7.0.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (0.8.7)\n","Collecting iopath>=0.1.2\n","  Downloading https://files.pythonhosted.org/packages/7a/9a/87a281c8cfc0ad1fceb228a4f854d02f19b2c2395476dd573327709b52ae/iopath-0.1.2.tar.gz\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Building wheels for collected packages: fvcore, pyyaml, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.2-cp36-none-any.whl size=44576 sha256=ffeb696cd997a6daf3d232bbd43546b9cd925d5568f58f457c0c8d0125ff5aa0\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-xyssig4n/wheels/04/a4/85/e50340018c00ae6e07e891fed78895891da33700e90a68aa05\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=56a02cca4ed72a5aac932db5bd0dc1b3eb2114eeb0440c91b282dcff2ba558b4\n","  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.2-cp36-none-any.whl size=10508 sha256=cef7bb74aeda4ed0454251c462e2405bd2550f7d98688d14809e0d11cef3917c\n","  Stored in directory: /root/.cache/pip/wheels/9e/01/e4/1b68f5a2a6b9450ea4246d91840a77e1169f7d4722d76bbc47\n","Successfully built fvcore pyyaml iopath\n","Installing collected packages: pyyaml, yacs, portalocker, iopath, fvcore\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed fvcore-0.1.2 iopath-0.1.2 portalocker-2.0.0 pyyaml-5.3.1 yacs-0.1.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U_ybOoDwHc3L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644444996,"user_tz":-480,"elapsed":3390,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"5eeb6020-f6ef-4c8b-de06-286ba0a03872"},"source":["pip install simplejson"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting simplejson\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/96/1e6b19045375890068d7342cbe280dd64ae73fd90b9735b5efb8d1e044a1/simplejson-3.17.2-cp36-cp36m-manylinux2010_x86_64.whl (127kB)\n","\r\u001b[K     |██▋                             | 10kB 22.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 30kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 40kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 51kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 61kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 71kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 81kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 92kB 13.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 102kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 112kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 122kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 12.3MB/s \n","\u001b[?25hInstalling collected packages: simplejson\n","Successfully installed simplejson-3.17.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sLK3gmfSHj-e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644455041,"user_tz":-480,"elapsed":8427,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"ae10e22f-871d-4b14-cc27-3b941cc19516"},"source":["pip install conda"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting conda\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/4e/c533c3136427be62c38cc0e038cabf167bb54489c2ced2f6df903c456861/conda-4.3.16.tar.gz (299kB)\n","\u001b[K     |████████████████████████████████| 307kB 26.6MB/s \n","\u001b[?25hCollecting pycosat>=0.6.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/fd/e38d68774c0a345b0090d608a90f1fbf423970d812f7ec7aef9ac024e648/pycosat-0.6.3.zip (66kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.12.4 in /usr/local/lib/python3.6/dist-packages (from conda) (2.23.0)\n","Collecting ruamel.yaml>=0.11.14\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/39/186f14f3836ac5d2a6a042c8de69988770e8b9abb537610edc429e4914aa/ruamel.yaml-0.16.12-py2.py3-none-any.whl (111kB)\n","\u001b[K     |████████████████████████████████| 112kB 20.2MB/s \n","\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.12.4->conda) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.12.4->conda) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.12.4->conda) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.12.4->conda) (3.0.4)\n","Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/ff/ec25dc01ef04232a9e68ff18492e37dfa01f1f58172e702ad4f38536d41b/ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549kB)\n","\u001b[K     |████████████████████████████████| 552kB 32.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: conda, pycosat\n","  Building wheel for conda (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for conda: filename=conda-4.3.16-cp36-none-any.whl size=336939 sha256=03c405de81832ca8cb213bbee5304610044d75795d8f61dc9f1ed1f6ce5c7399\n","  Stored in directory: /root/.cache/pip/wheels/a3/50/79/302742d53e2231ec545cb3791abfdd24de234021ed8e0588a0\n","  Building wheel for pycosat (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycosat: filename=pycosat-0.6.3-cp36-cp36m-linux_x86_64.whl size=142836 sha256=bfe441c2e9d15b221c31280e96fb49a350d5a1d0a90f8a7f9f1a6dd97fd48023\n","  Stored in directory: /root/.cache/pip/wheels/c4/67/ff/5570304e45814eccef48a3c69c3af25d0456ed3a34eddbbe38\n","Successfully built conda pycosat\n","Installing collected packages: pycosat, ruamel.yaml.clib, ruamel.yaml, conda\n","Successfully installed conda-4.3.16 pycosat-0.6.3 ruamel.yaml-0.16.12 ruamel.yaml.clib-0.2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QvKpLkVrHt1y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644479306,"user_tz":-480,"elapsed":7354,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"a8e5adcd-7eac-420b-ef3d-105cb10dda66"},"source":["pip install av"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting av\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/62/9a992be76f8e13ce0e3a24a838191b546805545116f9fc869bd11bd21b5f/av-8.0.2-cp36-cp36m-manylinux2010_x86_64.whl (36.9MB)\n","\u001b[K     |████████████████████████████████| 36.9MB 86kB/s \n","\u001b[?25hInstalling collected packages: av\n","Successfully installed av-8.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ed2bqBQHH5Bj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644483885,"user_tz":-480,"elapsed":3162,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"c7aeb7f1-787b-45b0-e4e8-28f4eed418e8"},"source":["pip install psutil"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jUc17o_4IE6t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644501009,"user_tz":-480,"elapsed":3078,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"07685dbf-60a0-4072-b318-2fa88780cce6"},"source":["pip install tensorboard"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (2.4.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.10.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (50.3.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.17.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.7.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.32.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.36.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.4.2)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.19.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.15.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.3.3)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.12.4)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard) (3.3.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4A5gVH-VIKiL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644516996,"user_tz":-480,"elapsed":3082,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"d4c0c488-7ab0-4695-881f-e8dc7217f92a"},"source":["pip install moviepy"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (0.2.3.5)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from moviepy) (1.19.4)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.41.1)\n","Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (2.4.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.0.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cTGNlwSMIPk8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644534882,"user_tz":-480,"elapsed":10547,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"8c5ccd1f-2c77-4883-b2f5-18dff474a840"},"source":[" pip install -U 'git+https://github.com/facebookresearch/fvcore.git' 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/facebookresearch/fvcore.git\n","  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-unx9xqh_\n","  Running command git clone -q https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-unx9xqh_\n","Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-ldztwhxv\n","  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-ldztwhxv\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (1.19.4)\n","Requirement already satisfied, skipping upgrade: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (0.1.8)\n","Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (5.3.1)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (4.41.1)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (1.1.0)\n","Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (7.0.0)\n","Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (0.8.7)\n","Requirement already satisfied, skipping upgrade: iopath>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (0.1.2)\n","Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (50.3.2)\n","Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.21)\n","Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.2)\n","Requirement already satisfied, skipping upgrade: portalocker in /usr/local/lib/python3.6/dist-packages (from iopath>=0.1.2->fvcore==0.1.2) (2.0.0)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.1)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n","Building wheels for collected packages: fvcore, pycocotools\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.2-cp36-none-any.whl size=44576 sha256=8741492f19d41af08e3709bd55e7e74a8632ae534f08b48e878fcfc3d7efc62c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-6n8qjci0/wheels/48/53/79/3c6485543a4455a0006f5db590ab9957622b6227011941de06\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=265575 sha256=5485157b1c95e8974b96fb126f348195ff4bf883cbb35804b22f0d08f7bbc6b9\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-6n8qjci0/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n","Successfully built fvcore pycocotools\n","Installing collected packages: fvcore, pycocotools\n","  Found existing installation: fvcore 0.1.2\n","    Uninstalling fvcore-0.1.2:\n","      Successfully uninstalled fvcore-0.1.2\n","  Found existing installation: pycocotools 2.0.2\n","    Uninstalling pycocotools-2.0.2:\n","      Successfully uninstalled pycocotools-2.0.2\n","Successfully installed fvcore-0.1.2 pycocotools-2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yj0MroJxIa-E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644787701,"user_tz":-480,"elapsed":229140,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"71ace4da-1e1b-4769-a1b6-2483428ff6ed"},"source":["!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/Staniwnl/detectron2.git\n","  Cloning https://github.com/Staniwnl/detectron2.git to /tmp/pip-req-build-7a3bv7pw\n","  Running command git clone -q https://github.com/Staniwnl/detectron2.git /tmp/pip-req-build-7a3bv7pw\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (1.1.0)\n","Collecting Pillow>=7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/19/d4c25111d36163698396f93c363114cf1cddbacb24744f6612f25b6aa3d0/Pillow-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 17.8MB/s \n","\u001b[?25hRequirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (0.1.8)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (0.8.7)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (1.3.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (3.2.2)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (4.41.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (2.4.0)\n","Requirement already satisfied: fvcore>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (0.1.2)\n","Collecting pycocotools>=2.0.2\n","  Downloading https://files.pythonhosted.org/packages/de/df/056875d697c45182ed6d2ae21f62015896fdb841906fe48e7268e791c467/pycocotools-2.0.2.tar.gz\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (0.16.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (1.3.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2==0.3) (5.3.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (2.8.1)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (1.19.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (2.4.7)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.17.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (0.10.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (0.4.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (3.3.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (50.3.2)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (3.12.4)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.32.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.15.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.7.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (0.36.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (2.23.0)\n","Requirement already satisfied: iopath>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.2->detectron2==0.3) (0.1.2)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.2->detectron2==0.3) (0.29.21)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.3) (4.2.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.3) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.3) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.3) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.3) (3.3.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (1.24.3)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from iopath>=0.1.2->fvcore>=0.1.2->detectron2==0.3) (2.0.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->detectron2==0.3) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.3) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.3) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.3) (3.7.4.3)\n","Building wheels for collected packages: detectron2, pycocotools\n","  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for detectron2: filename=detectron2-0.3-cp36-cp36m-linux_x86_64.whl size=5568766 sha256=414cb563c2fc6378b1880d219742c6b861b9aa938714556b4152ce5f40dcc4b0\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-a9nygasa/wheels/4d/ee/47/2a8b9ec8a0fa27cb2577b04f62f499888453bfff3fbb9ad267\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp36-cp36m-linux_x86_64.whl size=265639 sha256=c2a69890ee3c0610e7fff9b6c8e40bed0dda36e4d00ef0819b17946b81014854\n","  Stored in directory: /root/.cache/pip/wheels/68/a5/e7/56401832f23d0b2db351c5b682e466cb4841960b086da65e4e\n","Successfully built detectron2 pycocotools\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: Pillow, pycocotools, detectron2\n","  Found existing installation: Pillow 7.0.0\n","    Uninstalling Pillow-7.0.0:\n","      Successfully uninstalled Pillow-7.0.0\n","  Found existing installation: pycocotools 2.0\n","    Uninstalling pycocotools-2.0:\n","      Successfully uninstalled pycocotools-2.0\n","Successfully installed Pillow-8.0.1 detectron2-0.3 pycocotools-2.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P4UTDU_sgvvP","executionInfo":{"status":"ok","timestamp":1608644817144,"user_tz":-480,"elapsed":4312,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"7f473e20-ae5f-46ba-ff27-441af4948666"},"source":["pip install -U 'git+https://github.com/facebookresearch/iopath'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/facebookresearch/iopath\n","  Cloning https://github.com/facebookresearch/iopath to /tmp/pip-req-build-q7apo8dn\n","  Running command git clone -q https://github.com/facebookresearch/iopath /tmp/pip-req-build-q7apo8dn\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from iopath==0.1.2) (4.41.1)\n","Requirement already satisfied, skipping upgrade: portalocker in /usr/local/lib/python3.6/dist-packages (from iopath==0.1.2) (2.0.0)\n","Building wheels for collected packages: iopath\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.2-cp36-none-any.whl size=11580 sha256=7492e543dc998df45fa07795516b65176ee8420c7efd2f9248ecad8003ba1472\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ixo54wes/wheels/c3/67/ba/08e69262171ec0da0fd614e8d381c0f86fe10190dc3c3b5413\n","Successfully built iopath\n","Installing collected packages: iopath\n","  Found existing installation: iopath 0.1.2\n","    Uninstalling iopath-0.1.2:\n","      Successfully uninstalled iopath-0.1.2\n","Successfully installed iopath-0.1.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ChPcoZitKtbL"},"source":["import os\n","os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/SlowFast\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EMMRDjAtLARG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644821350,"user_tz":-480,"elapsed":1098,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"a7d530f3-460a-47cc-9ef7-b5459756125d"},"source":["cd slowfast"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/SlowFast/slowfast\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_oVoWpPcLGbk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608644831964,"user_tz":-480,"elapsed":10202,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"bb9822ee-9099-4d6b-e0ef-f6066dbf4f1a"},"source":["!python setup.py build develop"],"execution_count":null,"outputs":[{"output_type":"stream","text":["running build\n","running build_py\n","copying slowfast/datasets/ava_helper.py -> build/lib/slowfast/datasets\n","copying slowfast/datasets/ava_dataset.py -> build/lib/slowfast/datasets\n","running develop\n","running egg_info\n","writing slowfast.egg-info/PKG-INFO\n","writing dependency_links to slowfast.egg-info/dependency_links.txt\n","writing requirements to slowfast.egg-info/requires.txt\n","writing top-level names to slowfast.egg-info/top_level.txt\n","writing manifest file 'slowfast.egg-info/SOURCES.txt'\n","running build_ext\n","Creating /usr/local/lib/python3.6/dist-packages/slowfast.egg-link (link to .)\n","Adding slowfast 1.0 to easy-install.pth file\n","\n","Installed /content/gdrive/My Drive/Colab Notebooks/SlowFast/slowfast\n","Processing dependencies for slowfast==1.0\n","Searching for tensorboard==2.4.0\n","Best match: tensorboard 2.4.0\n","Adding tensorboard 2.4.0 to easy-install.pth file\n","Installing tensorboard script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for sklearn==0.0\n","Best match: sklearn 0.0\n","Adding sklearn 0.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for torchvision==0.6.1+cu101\n","Best match: torchvision 0.6.1+cu101\n","Adding torchvision 0.6.1+cu101 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for pandas==1.1.5\n","Best match: pandas 1.1.5\n","Adding pandas 1.1.5 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for opencv-python==4.1.2.30\n","Best match: opencv-python 4.1.2.30\n","Adding opencv-python 4.1.2.30 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for detectron2==0.3\n","Best match: detectron2 0.3\n","Adding detectron2 0.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for matplotlib==3.2.2\n","Best match: matplotlib 3.2.2\n","Adding matplotlib 3.2.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for psutil==5.4.8\n","Best match: psutil 5.4.8\n","Adding psutil 5.4.8 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for tqdm==4.41.1\n","Best match: tqdm 4.41.1\n","Adding tqdm 4.41.1 to easy-install.pth file\n","Installing tqdm script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for simplejson==3.17.2\n","Best match: simplejson 3.17.2\n","Adding simplejson 3.17.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for termcolor==1.1.0\n","Best match: termcolor 1.1.0\n","Adding termcolor 1.1.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for av==8.0.2\n","Best match: av 8.0.2\n","Adding av 8.0.2 to easy-install.pth file\n","Installing pyav script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for PyYAML==5.3.1\n","Best match: PyYAML 5.3.1\n","Adding PyYAML 5.3.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for yacs==0.1.8\n","Best match: yacs 0.1.8\n","Adding yacs 0.1.8 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for tensorboard-plugin-wit==1.7.0\n","Best match: tensorboard-plugin-wit 1.7.0\n","Adding tensorboard-plugin-wit 1.7.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for grpcio==1.32.0\n","Best match: grpcio 1.32.0\n","Adding grpcio 1.32.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for Werkzeug==1.0.1\n","Best match: Werkzeug 1.0.1\n","Adding Werkzeug 1.0.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for absl-py==0.10.0\n","Best match: absl-py 0.10.0\n","Adding absl-py 0.10.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for numpy==1.19.4\n","Best match: numpy 1.19.4\n","Adding numpy 1.19.4 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.6 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for setuptools==50.3.2\n","Best match: setuptools 50.3.2\n","Adding setuptools 50.3.2 to easy-install.pth file\n","Installing easy_install script to /usr/local/bin\n","Installing easy_install-3.8 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for six==1.15.0\n","Best match: six 1.15.0\n","Adding six 1.15.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for wheel==0.36.2\n","Best match: wheel 0.36.2\n","Adding wheel 0.36.2 to easy-install.pth file\n","Installing wheel script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for google-auth==1.17.2\n","Best match: google-auth 1.17.2\n","Adding google-auth 1.17.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for Markdown==3.3.3\n","Best match: Markdown 3.3.3\n","Adding Markdown 3.3.3 to easy-install.pth file\n","Installing markdown_py script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for protobuf==3.12.4\n","Best match: protobuf 3.12.4\n","Adding protobuf 3.12.4 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for requests==2.23.0\n","Best match: requests 2.23.0\n","Adding requests 2.23.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for google-auth-oauthlib==0.4.2\n","Best match: google-auth-oauthlib 0.4.2\n","Adding google-auth-oauthlib 0.4.2 to easy-install.pth file\n","Installing google-oauthlib-tool script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for scikit-learn==0.22.2.post1\n","Best match: scikit-learn 0.22.2.post1\n","Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for torch==1.5.1+cu101\n","Best match: torch 1.5.1+cu101\n","Adding torch 1.5.1+cu101 to easy-install.pth file\n","Installing convert-caffe2-to-onnx script to /usr/local/bin\n","Installing convert-onnx-to-caffe2 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for Pillow==8.0.1\n","Best match: Pillow 8.0.1\n","Adding Pillow 8.0.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for pytz==2018.9\n","Best match: pytz 2018.9\n","Adding pytz 2018.9 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for python-dateutil==2.8.1\n","Best match: python-dateutil 2.8.1\n","Adding python-dateutil 2.8.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for pycocotools==2.0.2\n","Best match: pycocotools 2.0.2\n","Adding pycocotools 2.0.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for fvcore==0.1.2\n","Best match: fvcore 0.1.2\n","Adding fvcore 0.1.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for future==0.16.0\n","Best match: future 0.16.0\n","Adding future 0.16.0 to easy-install.pth file\n","Installing futurize script to /usr/local/bin\n","Installing pasteurize script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for cloudpickle==1.3.0\n","Best match: cloudpickle 1.3.0\n","Adding cloudpickle 1.3.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for tabulate==0.8.7\n","Best match: tabulate 0.8.7\n","Adding tabulate 0.8.7 to easy-install.pth file\n","Installing tabulate script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for pydot==1.3.0\n","Best match: pydot 1.3.0\n","Adding pydot 1.3.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for cycler==0.10.0\n","Best match: cycler 0.10.0\n","Adding cycler 0.10.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for kiwisolver==1.3.1\n","Best match: kiwisolver 1.3.1\n","Adding kiwisolver 1.3.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for pyparsing==2.4.7\n","Best match: pyparsing 2.4.7\n","Adding pyparsing 2.4.7 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for rsa==4.6\n","Best match: rsa 4.6\n","Adding rsa 4.6 to easy-install.pth file\n","Installing pyrsa-decrypt script to /usr/local/bin\n","Installing pyrsa-encrypt script to /usr/local/bin\n","Installing pyrsa-keygen script to /usr/local/bin\n","Installing pyrsa-priv2pub script to /usr/local/bin\n","Installing pyrsa-sign script to /usr/local/bin\n","Installing pyrsa-verify script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for cachetools==4.2.0\n","Best match: cachetools 4.2.0\n","Adding cachetools 4.2.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for pyasn1-modules==0.2.8\n","Best match: pyasn1-modules 0.2.8\n","Adding pyasn1-modules 0.2.8 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for importlib-metadata==3.3.0\n","Best match: importlib-metadata 3.3.0\n","Adding importlib-metadata 3.3.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for chardet==3.0.4\n","Best match: chardet 3.0.4\n","Adding chardet 3.0.4 to easy-install.pth file\n","Installing chardetect script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for certifi==2020.12.5\n","Best match: certifi 2020.12.5\n","Adding certifi 2020.12.5 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for urllib3==1.24.3\n","Best match: urllib3 1.24.3\n","Adding urllib3 1.24.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for idna==2.10\n","Best match: idna 2.10\n","Adding idna 2.10 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for requests-oauthlib==1.3.0\n","Best match: requests-oauthlib 1.3.0\n","Adding requests-oauthlib 1.3.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for scipy==1.4.1\n","Best match: scipy 1.4.1\n","Adding scipy 1.4.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for joblib==1.0.0\n","Best match: joblib 1.0.0\n","Adding joblib 1.0.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for Cython==0.29.21\n","Best match: Cython 0.29.21\n","Adding Cython 0.29.21 to easy-install.pth file\n","Installing cygdb script to /usr/local/bin\n","Installing cython script to /usr/local/bin\n","Installing cythonize script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for iopath==0.1.2\n","Best match: iopath 0.1.2\n","Adding iopath 0.1.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for pyasn1==0.4.8\n","Best match: pyasn1 0.4.8\n","Adding pyasn1 0.4.8 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for zipp==3.4.0\n","Best match: zipp 3.4.0\n","Adding zipp 3.4.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for typing-extensions==3.7.4.3\n","Best match: typing-extensions 3.7.4.3\n","Adding typing-extensions 3.7.4.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for oauthlib==3.1.0\n","Best match: oauthlib 3.1.0\n","Adding oauthlib 3.1.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for portalocker==2.0.0\n","Best match: portalocker 2.0.0\n","Adding portalocker 2.0.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Finished processing dependencies for slowfast==1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MUOTEqQ0LNfJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608646438637,"user_tz":-480,"elapsed":269811,"user":{"displayName":"Owen Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrQWGu2Y8MmqS5PfDuHu02T5rCnjSNiK6-EMQV=s64","userId":"14003705374634260831"}},"outputId":"d2925e1b-ab61-45c1-d240-fcf06d17889e"},"source":["!python tools/run_net.py --cfg demo/AVA/SLOWFAST_32x2_R101_50_50_train_AMI.yaml "],"execution_count":null,"outputs":[{"output_type":"stream","text":["** fvcore version of PathManager will be deprecated soon. **\n","** Please migrate to the version in iopath repo. **\n","https://github.com/facebookresearch/iopath \n","\n","** fvcore version of PathManager will be deprecated soon. **\n","** Please migrate to the version in iopath repo. **\n","https://github.com/facebookresearch/iopath \n","\n","[12/22 14:09:31][INFO] train_net.py: 379: Train with config:\n","[12/22 14:09:31][INFO] train_net.py: 380: {'AVA': {'ANNOTATION_DIR': 'data/ava/frame_lists/',\n","         'BGR': False,\n","         'DETECTION_SCORE_THRESH': 0.8,\n","         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',\n","         'FRAME_DIR': 'data/ava/frames/',\n","         'FRAME_LIST_DIR': 'data/ava/frame_lists/',\n","         'FULL_TEST_ON_VAL': True,\n","         'GROUNDTRUTH_FILE': 'val_groundtruth.csv',\n","         'IMG_PROC_BACKEND': 'cv2',\n","         'LABEL_MAP_FILE': 'label_map_file.pbtxt',\n","         'TEST_FORCE_FLIP': False,\n","         'TEST_LISTS': ['val.csv'],\n","         'TEST_PREDICT_BOX_LISTS': ['val_groundtruth.csv'],\n","         'TRAIN_GT_BOX_LISTS': ['train_groundtruth.csv'],\n","         'TRAIN_LISTS': ['train.csv'],\n","         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],\n","         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],\n","                              [-0.5808, -0.0045, -0.814],\n","                              [-0.5836, -0.6948, 0.4203]],\n","         'TRAIN_PCA_JITTER_ONLY': True,\n","         'TRAIN_PREDICT_BOX_LISTS': [],\n","         'TRAIN_USE_COLOR_AUGMENTATION': False},\n"," 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),\n"," 'BN': {'NORM_TYPE': 'batchnorm',\n","        'NUM_BATCHES_PRECISE': 200,\n","        'NUM_SPLITS': 1,\n","        'NUM_SYNC_DEVICES': 1,\n","        'USE_PRECISE_STATS': False,\n","        'WEIGHT_DECAY': 0.0},\n"," 'DATA': {'DECODING_BACKEND': 'pyav',\n","          'ENSEMBLE_METHOD': 'sum',\n","          'INPUT_CHANNEL_NUM': [3, 3],\n","          'INV_UNIFORM_SAMPLE': False,\n","          'MEAN': [0.45, 0.45, 0.45],\n","          'MULTI_LABEL': False,\n","          'NUM_FRAMES': 32,\n","          'PATH_LABEL_SEPARATOR': ' ',\n","          'PATH_PREFIX': '/content/gdrive/My Drive/Colab '\n","                         'Notebooks/SlowFast/slowfast/',\n","          'PATH_TO_DATA_DIR': 'data/ava/',\n","          'RANDOM_FLIP': True,\n","          'REVERSE_INPUT_CHANNEL': False,\n","          'SAMPLING_RATE': 2,\n","          'STD': [0.225, 0.225, 0.225],\n","          'TARGET_FPS': 30,\n","          'TEST_CROP_SIZE': 256,\n","          'TRAIN_CROP_SIZE': 224,\n","          'TRAIN_JITTER_SCALES': [256, 320]},\n"," 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,\n","                 'NUM_WORKERS': 1,\n","                 'PIN_MEMORY': True},\n"," 'DEMO': {'BUFFER_SIZE': 0,\n","          'CLIP_VIS_SIZE': 15,\n","          'COMMON_CLASS_NAMES': ['watch (a person)',\n","                                 'talk to (e.g., self, a person, a group)',\n","                                 'listen to (a person)',\n","                                 'touch (an object)',\n","                                 'carry/hold (an object)',\n","                                 'walk',\n","                                 'sit',\n","                                 'lie/sleep',\n","                                 'bend/bow (at the waist)'],\n","          'COMMON_CLASS_THRES': 0.8,\n","          'DETECTRON2_CFG': 'COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml',\n","          'DETECTRON2_THRESH': 0.4,\n","          'DETECTRON2_WEIGHTS': './demo/AVA/model_0009999.pth',\n","          'DISPLAY_HEIGHT': 0,\n","          'DISPLAY_WIDTH': 0,\n","          'ENABLE': False,\n","          'FPS': 25,\n","          'GT_BOXES': '',\n","          'INPUT_FORMAT': 'BGR',\n","          'INPUT_VIDEO': './EN2001a.Corner_cut.avi',\n","          'LABEL_FILE_PATH': './demo/AVA/ava_classnames.json',\n","          'NUM_CLIPS_SKIP': -1,\n","          'NUM_VIS_INSTANCES': 2,\n","          'OUTPUT_FILE': './EN2001a.Corner_cut_output.avi',\n","          'OUTPUT_FPS': 25,\n","          'PREDS_BOXES': '',\n","          'SLOWMO': 1,\n","          'STARTING_SECOND': 900,\n","          'THREAD_ENABLE': False,\n","          'UNCOMMON_CLASS_THRES': 0.9,\n","          'VIS_MODE': 'top-k',\n","          'WEBCAM': -1},\n"," 'DETECTION': {'ALIGNED': True,\n","               'ENABLE': True,\n","               'ROI_XFORM_RESOLUTION': 7,\n","               'SPATIAL_SCALE_FACTOR': 16},\n"," 'DIST_BACKEND': 'nccl',\n"," 'LOG_MODEL_INFO': True,\n"," 'LOG_PERIOD': 10,\n"," 'MODEL': {'ARCH': 'slowfast',\n","           'DROPCONNECT_RATE': 0.0,\n","           'DROPOUT_RATE': 0.5,\n","           'FC_INIT_STD': 0.01,\n","           'HEAD_ACT': 'sigmoid',\n","           'LOSS_FUNC': 'bce',\n","           'MODEL_NAME': 'SlowFast',\n","           'MULTI_PATHWAY_ARCH': ['slowfast'],\n","           'NUM_CLASSES': 7,\n","           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},\n"," 'MULTIGRID': {'BN_BASE_SIZE': 8,\n","               'DEFAULT_B': 0,\n","               'DEFAULT_S': 0,\n","               'DEFAULT_T': 0,\n","               'EPOCH_FACTOR': 1.5,\n","               'EVAL_FREQ': 3,\n","               'LONG_CYCLE': False,\n","               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),\n","                                      (0.5, 0.7071067811865476),\n","                                      (0.5, 1),\n","                                      (1, 1)],\n","               'LONG_CYCLE_SAMPLING_RATE': 0,\n","               'SHORT_CYCLE': False,\n","               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},\n"," 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],\n","              'INSTANTIATION': 'dot_product',\n","              'LOCATION': [[[], []], [[], []], [[6, 13, 20], []], [[], []]],\n","              'POOL': [[[2, 2, 2], [2, 2, 2]],\n","                       [[2, 2, 2], [2, 2, 2]],\n","                       [[2, 2, 2], [2, 2, 2]],\n","                       [[2, 2, 2], [2, 2, 2]]]},\n"," 'NUM_GPUS': 1,\n"," 'NUM_SHARDS': 1,\n"," 'OUTPUT_DIR': './output',\n"," 'RESNET': {'DEPTH': 101,\n","            'INPLACE_RELU': True,\n","            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],\n","            'NUM_GROUPS': 1,\n","            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],\n","            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],\n","            'STRIDE_1X1': False,\n","            'TRANS_FUNC': 'bottleneck_transform',\n","            'WIDTH_PER_GROUP': 64,\n","            'ZERO_INIT_FINAL_BN': True},\n"," 'RNG_SEED': 0,\n"," 'SHARD_ID': 0,\n"," 'SLOWFAST': {'ALPHA': 4,\n","              'BETA_INV': 8,\n","              'FUSION_CONV_CHANNEL_RATIO': 2,\n","              'FUSION_KERNEL_SZ': 7},\n"," 'SOLVER': {'BASE_LR': 0.1,\n","            'BASE_LR_SCALE_NUM_SHARDS': False,\n","            'COSINE_END_LR': 0.0,\n","            'DAMPENING': 0.0,\n","            'GAMMA': 0.1,\n","            'LRS': [1, 0.1, 0.01, 0.001],\n","            'LR_POLICY': 'steps_with_relative_lrs',\n","            'MAX_EPOCH': 20,\n","            'MOMENTUM': 0.9,\n","            'NESTEROV': True,\n","            'OPTIMIZING_METHOD': 'sgd',\n","            'STEPS': [0, 10, 15, 20],\n","            'STEP_SIZE': 1,\n","            'WARMUP_EPOCHS': 5.0,\n","            'WARMUP_FACTOR': 0.1,\n","            'WARMUP_START_LR': 0.000125,\n","            'WEIGHT_DECAY': 1e-07},\n"," 'TENSORBOARD': {'CATEGORIES_PATH': '',\n","                 'CLASS_NAMES_PATH': '',\n","                 'CONFUSION_MATRIX': {'ENABLE': False,\n","                                      'FIGSIZE': [8, 8],\n","                                      'SUBSET_PATH': ''},\n","                 'ENABLE': False,\n","                 'HISTOGRAM': {'ENABLE': False,\n","                               'FIGSIZE': [8, 8],\n","                               'SUBSET_PATH': '',\n","                               'TOPK': 10},\n","                 'LOG_DIR': '',\n","                 'MODEL_VIS': {'ACTIVATIONS': False,\n","                               'COLORMAP': 'Pastel2',\n","                               'ENABLE': False,\n","                               'GRAD_CAM': {'COLORMAP': 'viridis',\n","                                            'ENABLE': True,\n","                                            'LAYER_LIST': [],\n","                                            'USE_TRUE_LABEL': False},\n","                               'INPUT_VIDEO': False,\n","                               'LAYER_LIST': [],\n","                               'MODEL_WEIGHTS': False,\n","                               'TOPK_PREDS': 1},\n","                 'PREDICTIONS_PATH': '',\n","                 'WRONG_PRED_VIS': {'ENABLE': False,\n","                                    'SUBSET_PATH': '',\n","                                    'TAG': 'Incorrectly classified videos.'}},\n"," 'TEST': {'BATCH_SIZE': 8,\n","          'CHECKPOINT_FILE_PATH': '',\n","          'CHECKPOINT_TYPE': 'pytorch',\n","          'DATASET': 'ava',\n","          'ENABLE': False,\n","          'NUM_ENSEMBLE_VIEWS': 10,\n","          'NUM_SPATIAL_CROPS': 3,\n","          'SAVE_RESULTS_PATH': ''},\n"," 'TRAIN': {'AUTO_RESUME': False,\n","           'BATCH_SIZE': 1,\n","           'CHECKPOINT_CLEAR_NAME_PATTERN': (),\n","           'CHECKPOINT_EPOCH_RESET': False,\n","           'CHECKPOINT_FILE_PATH': '',\n","           'CHECKPOINT_INFLATE': False,\n","           'CHECKPOINT_PERIOD': 1,\n","           'CHECKPOINT_TYPE': 'caffe2',\n","           'DATASET': 'ava',\n","           'ENABLE': True,\n","           'EVAL_PERIOD': 1},\n"," 'X3D': {'BN_LIN5': False,\n","         'BOTTLENECK_FACTOR': 1.0,\n","         'CHANNELWISE_3x3x3': True,\n","         'DEPTH_FACTOR': 1.0,\n","         'DIM_C1': 12,\n","         'DIM_C5': 2048,\n","         'SCALE_RES2': False,\n","         'WIDTH_FACTOR': 1.0}}\n","[12/22 14:09:36][INFO] misc.py: 168: Model:\n","SlowFast(\n","  (s1): VideoModelStem(\n","    (pathway0_stem): ResNetBasicStem(\n","      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)\n","      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n","    )\n","    (pathway1_stem): ResNetBasicStem(\n","      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)\n","      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n","    )\n","  )\n","  (s1_fuse): FuseFastToSlow(\n","    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)\n","    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (s2): ResStage(\n","    (pathway0_res0): ResBlock(\n","      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)\n","      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res1): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res2): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res0): ResBlock(\n","      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)\n","      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res1): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res2): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (s2_fuse): FuseFastToSlow(\n","    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)\n","    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)\n","  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)\n","  (s3): ResStage(\n","    (pathway0_res0): ResBlock(\n","      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)\n","      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res1): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res2): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res3): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res0): ResBlock(\n","      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)\n","      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res1): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res2): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res3): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (s3_fuse): FuseFastToSlow(\n","    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)\n","    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (s4): ResStage(\n","    (pathway0_res0): ResBlock(\n","      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)\n","      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res1): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res2): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res3): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res4): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res5): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res6): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_nonlocal6): Nonlocal(\n","      (conv_theta): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n","      (conv_phi): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n","      (conv_g): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n","      (conv_out): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n","      (bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (pool): MaxPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=1, ceil_mode=False)\n","    )\n","    (pathway0_res7): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res8): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res9): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res10): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res11): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res12): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res13): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_nonlocal13): Nonlocal(\n","      (conv_theta): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n","      (conv_phi): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n","      (conv_g): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n","      (conv_out): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n","      (bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (pool): MaxPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=1, ceil_mode=False)\n","    )\n","    (pathway0_res14): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res15): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res16): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res17): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res18): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res19): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res20): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_nonlocal20): Nonlocal(\n","      (conv_theta): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n","      (conv_phi): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n","      (conv_g): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n","      (conv_out): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n","      (bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (pool): MaxPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=1, ceil_mode=False)\n","    )\n","    (pathway0_res21): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res22): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1024, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res0): ResBlock(\n","      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)\n","      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res1): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res2): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res3): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res4): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res5): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res6): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res7): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res8): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res9): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res10): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res11): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res12): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res13): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res14): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res15): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res16): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res17): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res18): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res19): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res20): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res21): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res22): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)\n","        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (s4_fuse): FuseFastToSlow(\n","    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)\n","    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (s5): ResStage(\n","    (pathway0_res0): ResBlock(\n","      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)\n","      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)\n","        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res1): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)\n","        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway0_res2): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)\n","        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res0): ResBlock(\n","      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)\n","      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)\n","        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res1): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)\n","        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (pathway1_res2): ResBlock(\n","      (branch2): BottleneckTransform(\n","        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)\n","        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (a_relu): ReLU(inplace=True)\n","        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)\n","        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (b_relu): ReLU(inplace=True)\n","        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)\n","        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (head): ResNetRoIHead(\n","    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)\n","    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)\n","    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)\n","    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","    (projection): Linear(in_features=2304, out_features=7, bias=True)\n","    (act): Sigmoid()\n","  )\n",")\n","[12/22 14:09:36][INFO] misc.py: 169: Params: 59,260,495\n","[12/22 14:09:36][INFO] misc.py: 170: Mem: 0.2232828140258789 MB\n","/content/gdrive/My Drive/Colab Notebooks/SlowFast/slowfast/slowfast/models/head_helper.py:111: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n","  assert out.shape[2] == 1\n","/usr/local/lib/python3.6/dist-packages/detectron2/layers/roi_align.py:105: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n","  assert rois.dim() == 2 and rois.size(1) == 5\n","[12/22 14:09:36][WARNING] flop_count.py:  65: Skipped operation aten::batch_norm 215 time(s)\n","[12/22 14:09:36][WARNING] flop_count.py:  65: Skipped operation aten::max_pool3d 7 time(s)\n","[12/22 14:09:36][WARNING] flop_count.py:  65: Skipped operation aten::add 69 time(s)\n","[12/22 14:09:36][WARNING] flop_count.py:  65: Skipped operation aten::div 3 time(s)\n","[12/22 14:09:36][WARNING] flop_count.py:  65: Skipped operation aten::avg_pool3d 2 time(s)\n","[12/22 14:09:36][WARNING] flop_count.py:  65: Skipped operation prim::PythonOp 2 time(s)\n","[12/22 14:09:36][WARNING] flop_count.py:  65: Skipped operation aten::max_pool2d 2 time(s)\n","[12/22 14:09:36][WARNING] flop_count.py:  65: Skipped operation aten::sigmoid 1 time(s)\n","[12/22 14:09:36][INFO] misc.py: 173: Flops: 112.2272704 G\n","[12/22 14:09:37][WARNING] activation_count.py:  56: Skipped operation aten::batch_norm 215 time(s)\n","[12/22 14:09:37][WARNING] activation_count.py:  56: Skipped operation aten::max_pool3d 7 time(s)\n","[12/22 14:09:37][WARNING] activation_count.py:  56: Skipped operation aten::add 69 time(s)\n","[12/22 14:09:37][WARNING] activation_count.py:  56: Skipped operation aten::einsum 6 time(s)\n","[12/22 14:09:37][WARNING] activation_count.py:  56: Skipped operation aten::div 3 time(s)\n","[12/22 14:09:37][WARNING] activation_count.py:  56: Skipped operation aten::avg_pool3d 2 time(s)\n","[12/22 14:09:37][WARNING] activation_count.py:  56: Skipped operation prim::PythonOp 2 time(s)\n","[12/22 14:09:37][WARNING] activation_count.py:  56: Skipped operation aten::max_pool2d 2 time(s)\n","[12/22 14:09:37][WARNING] activation_count.py:  56: Skipped operation aten::sigmoid 1 time(s)\n","[12/22 14:09:37][INFO] misc.py: 178: Activations: 224.788487 M\n","[12/22 14:09:37][INFO] misc.py: 181: nvidia-smi\n","Tue Dec 22 14:09:37 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    32W /  70W |   3237MiB / 15079MiB |     13%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","[12/22 14:09:37][INFO] ava_helper.py:  62: Finished loading image paths from: data/ava/frame_lists/train.csv\n","[12/22 14:09:37][INFO] ava_helper.py: 107: Finished loading annotations from: data/ava/frame_lists/train_groundtruth.csv\n","[12/22 14:09:37][INFO] ava_helper.py: 109: Detection threshold: 0.8\n","[12/22 14:09:37][INFO] ava_helper.py: 110: Number of unique boxes: 12\n","[12/22 14:09:37][INFO] ava_helper.py: 111: Number of annotations: 12\n","1\n","1\n","[12/22 14:09:37][INFO] ava_helper.py: 157: 3 keyframes used.\n","[12/22 14:09:37][INFO] ava_dataset.py:  97: === AVA dataset summary ===\n","[12/22 14:09:37][INFO] ava_dataset.py:  98: Split: train\n","[12/22 14:09:37][INFO] ava_dataset.py:  99: Number of videos: 1\n","[12/22 14:09:37][INFO] ava_dataset.py: 103: Number of frames: 600\n","[12/22 14:09:37][INFO] ava_dataset.py: 104: Number of key frames: 3\n","[12/22 14:09:37][INFO] ava_dataset.py: 105: Number of boxes: 12.\n","[12/22 14:09:37][INFO] ava_helper.py:  62: Finished loading image paths from: data/ava/frame_lists/val.csv\n","[12/22 14:09:37][INFO] ava_helper.py: 107: Finished loading annotations from: data/ava/frame_lists/val_groundtruth.csv\n","[12/22 14:09:37][INFO] ava_helper.py: 109: Detection threshold: 0.8\n","[12/22 14:09:37][INFO] ava_helper.py: 110: Number of unique boxes: 6\n","[12/22 14:09:37][INFO] ava_helper.py: 111: Number of annotations: 6\n","1\n","1\n","[12/22 14:09:37][INFO] ava_helper.py: 157: 2 keyframes used.\n","[12/22 14:09:37][INFO] ava_dataset.py:  97: === AVA dataset summary ===\n","[12/22 14:09:37][INFO] ava_dataset.py:  98: Split: val\n","[12/22 14:09:37][INFO] ava_dataset.py:  99: Number of videos: 1\n","[12/22 14:09:37][INFO] ava_dataset.py: 103: Number of frames: 600\n","[12/22 14:09:37][INFO] ava_dataset.py: 104: Number of key frames: 2\n","[12/22 14:09:37][INFO] ava_dataset.py: 105: Number of boxes: 6.\n","[12/22 14:09:37][INFO] ava_helper.py:  62: Finished loading image paths from: data/ava/frame_lists/train.csv\n","[12/22 14:09:37][INFO] ava_helper.py:  62: Finished loading image paths from: data/ava/frame_lists/val.csv\n","[12/22 14:09:37][INFO] train_net.py: 419: Start epoch: 1\n","[12/22 14:10:31][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:10:31][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:10:31][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:10:31][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:10:32][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:10:32][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:10:32][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.6666666666666666,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.5333333333333333,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.6}\n","[12/22 14:10:32][INFO] ava_eval_helper.py: 171: AVA eval done in 0.538518 seconds.\n","[12/22 14:10:32][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.05/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"1\", \"gpu_mem\": \"2.57G\", \"map\": 0.60000, \"mode\": \"val\"}\n","[12/22 14:10:38][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:10:38][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:10:38][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:10:38][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:10:38][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:10:38][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:10:38][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.6666666666666666,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.5333333333333333,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.6}\n","[12/22 14:10:38][INFO] ava_eval_helper.py: 171: AVA eval done in 0.027757 seconds.\n","[12/22 14:10:38][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.07/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"2\", \"gpu_mem\": \"2.57G\", \"map\": 0.60000, \"mode\": \"val\"}\n","[12/22 14:10:44][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:10:44][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:10:44][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:10:44][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:10:44][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:10:44][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:10:44][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.5555555555555556,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.6000000000000001,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.5777777777777778}\n","[12/22 14:10:44][INFO] ava_eval_helper.py: 171: AVA eval done in 0.012849 seconds.\n","[12/22 14:10:44][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.08/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"3\", \"gpu_mem\": \"2.57G\", \"map\": 0.57778, \"mode\": \"val\"}\n","[12/22 14:10:51][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:10:51][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:10:51][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:10:51][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:10:51][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:10:51][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:10:51][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.2222222222222222,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.5333333333333333,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.37777777777777777}\n","[12/22 14:10:51][INFO] ava_eval_helper.py: 171: AVA eval done in 0.012666 seconds.\n","[12/22 14:10:51][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.07/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"4\", \"gpu_mem\": \"2.57G\", \"map\": 0.37778, \"mode\": \"val\"}\n","[12/22 14:10:58][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:10:58][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:10:58][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:10:58][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:10:58][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:10:58][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:10:58][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.4444444444444444,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.8,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.6222222222222222}\n","[12/22 14:10:58][INFO] ava_eval_helper.py: 171: AVA eval done in 0.018611 seconds.\n","[12/22 14:10:58][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.07/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"5\", \"gpu_mem\": \"2.57G\", \"map\": 0.62222, \"mode\": \"val\"}\n","[12/22 14:11:05][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:11:05][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:11:05][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:11:05][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:11:05][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:11:05][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:11:05][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.3,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.6333333333333333,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.4666666666666667}\n","[12/22 14:11:05][INFO] ava_eval_helper.py: 171: AVA eval done in 0.015754 seconds.\n","[12/22 14:11:05][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.07/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"6\", \"gpu_mem\": \"2.57G\", \"map\": 0.46667, \"mode\": \"val\"}\n","[12/22 14:11:16][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:11:16][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:11:16][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:11:16][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:11:22][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:11:22][INFO] ava_eval_helper.py: 305: \ttook 5 seconds.\n","[12/22 14:11:22][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.3,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.6333333333333333,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.4666666666666667}\n","[12/22 14:11:22][INFO] ava_eval_helper.py: 171: AVA eval done in 5.391734 seconds.\n","[12/22 14:11:22][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.07/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"7\", \"gpu_mem\": \"2.57G\", \"map\": 0.46667, \"mode\": \"val\"}\n","[12/22 14:11:30][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:11:30][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:11:30][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:11:30][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:11:30][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:11:30][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:11:30][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.3,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.6333333333333333,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.4666666666666667}\n","[12/22 14:11:30][INFO] ava_eval_helper.py: 171: AVA eval done in 0.018643 seconds.\n","[12/22 14:11:30][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.07/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"8\", \"gpu_mem\": \"2.57G\", \"map\": 0.46667, \"mode\": \"val\"}\n","[12/22 14:11:41][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:11:41][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:11:45][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:11:45][INFO] ava_eval_helper.py: 305: \ttook 4 seconds.\n","[12/22 14:11:45][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:11:45][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:11:45][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.3,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.76,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.53}\n","[12/22 14:11:45][INFO] ava_eval_helper.py: 171: AVA eval done in 4.589940 seconds.\n","[12/22 14:11:45][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.06/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"9\", \"gpu_mem\": \"2.57G\", \"map\": 0.53000, \"mode\": \"val\"}\n","[12/22 14:11:54][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:11:54][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:11:54][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:11:54][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:11:54][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:11:54][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:11:54][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.3,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.8,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.55}\n","[12/22 14:11:54][INFO] ava_eval_helper.py: 171: AVA eval done in 0.016432 seconds.\n","[12/22 14:11:54][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.54/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"10\", \"gpu_mem\": \"2.57G\", \"map\": 0.55000, \"mode\": \"val\"}\n","[12/22 14:12:05][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:12:05][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:12:05][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:12:05][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:12:07][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:12:07][INFO] ava_eval_helper.py: 305: \ttook 2 seconds.\n","[12/22 14:12:07][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.3,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.8,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.55}\n","[12/22 14:12:07][INFO] ava_eval_helper.py: 171: AVA eval done in 2.667023 seconds.\n","[12/22 14:12:07][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.63/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"11\", \"gpu_mem\": \"2.57G\", \"map\": 0.55000, \"mode\": \"val\"}\n","[12/22 14:12:18][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:12:18][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:12:18][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:12:18][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:12:21][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:12:21][INFO] ava_eval_helper.py: 305: \ttook 3 seconds.\n","[12/22 14:12:21][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.3333333333333333,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.8,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.5666666666666667}\n","[12/22 14:12:21][INFO] ava_eval_helper.py: 171: AVA eval done in 3.815189 seconds.\n","[12/22 14:12:21][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.63/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"12\", \"gpu_mem\": \"2.57G\", \"map\": 0.56667, \"mode\": \"val\"}\n","[12/22 14:12:34][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:12:34][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:12:34][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:12:34][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:12:34][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:12:34][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:12:34][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.6666666666666666,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.8,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.7333333333333334}\n","[12/22 14:12:34][INFO] ava_eval_helper.py: 171: AVA eval done in 0.015378 seconds.\n","[12/22 14:12:34][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.63/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"13\", \"gpu_mem\": \"2.57G\", \"map\": 0.73333, \"mode\": \"val\"}\n","[12/22 14:12:41][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:12:41][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:12:41][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:12:41][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:12:45][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:12:45][INFO] ava_eval_helper.py: 305: \ttook 4 seconds.\n","[12/22 14:12:45][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.6666666666666666,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.8,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.7333333333333334}\n","[12/22 14:12:45][INFO] ava_eval_helper.py: 171: AVA eval done in 4.345050 seconds.\n","[12/22 14:12:45][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.63/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"14\", \"gpu_mem\": \"2.57G\", \"map\": 0.73333, \"mode\": \"val\"}\n","[12/22 14:12:53][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:12:53][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:12:53][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:12:53][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:12:57][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:12:57][INFO] ava_eval_helper.py: 305: \ttook 3 seconds.\n","[12/22 14:12:57][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.6666666666666666,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.8,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.7333333333333334}\n","[12/22 14:12:57][INFO] ava_eval_helper.py: 171: AVA eval done in 3.793605 seconds.\n","[12/22 14:12:57][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.63/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"15\", \"gpu_mem\": \"2.57G\", \"map\": 0.73333, \"mode\": \"val\"}\n","[12/22 14:13:05][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:13:05][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:13:05][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:13:05][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:13:05][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:13:05][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:13:05][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.6666666666666666,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.8,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.7333333333333334}\n","[12/22 14:13:05][INFO] ava_eval_helper.py: 171: AVA eval done in 0.025079 seconds.\n","[12/22 14:13:05][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.64/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"16\", \"gpu_mem\": \"2.57G\", \"map\": 0.73333, \"mode\": \"val\"}\n","[12/22 14:13:16][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:13:16][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:13:21][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:13:21][INFO] ava_eval_helper.py: 305: \ttook 5 seconds.\n","[12/22 14:13:21][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:13:21][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:13:21][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.6666666666666666,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.8,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.7333333333333334}\n","[12/22 14:13:21][INFO] ava_eval_helper.py: 171: AVA eval done in 5.119826 seconds.\n","[12/22 14:13:21][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.64/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"17\", \"gpu_mem\": \"2.57G\", \"map\": 0.73333, \"mode\": \"val\"}\n","[12/22 14:13:28][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:13:28][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:13:29][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:13:29][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:13:29][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:13:29][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:13:29][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.6666666666666666,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.8,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.7333333333333334}\n","[12/22 14:13:29][INFO] ava_eval_helper.py: 171: AVA eval done in 0.113809 seconds.\n","[12/22 14:13:29][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.64/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"18\", \"gpu_mem\": \"2.57G\", \"map\": 0.73333, \"mode\": \"val\"}\n","[12/22 14:13:44][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:13:44][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:13:44][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:13:44][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:13:44][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:13:44][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:13:44][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.6666666666666666,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.8,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.7333333333333334}\n","[12/22 14:13:44][INFO] ava_eval_helper.py: 171: AVA eval done in 0.012246 seconds.\n","[12/22 14:13:44][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.65/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"19\", \"gpu_mem\": \"2.57G\", \"map\": 0.73333, \"mode\": \"val\"}\n","[12/22 14:13:52][INFO] ava_eval_helper.py: 161: Evaluating with 2 unique GT frames.\n","[12/22 14:13:52][INFO] ava_eval_helper.py: 163: Evaluating with 2 unique detection frames\n","[12/22 14:13:52][INFO] ava_eval_helper.py: 304: AVA results wrote to detections_latest.csv\n","[12/22 14:13:52][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:13:52][INFO] ava_eval_helper.py: 304: AVA results wrote to groundtruth_latest.csv\n","[12/22 14:13:52][INFO] ava_eval_helper.py: 305: \ttook 0 seconds.\n","[12/22 14:13:52][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 3 4 5 7]\n","{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/move': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/off_camera': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/other': 0.6666666666666666,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.8,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_screen': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand_whiteboard': nan,\n","  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take_notes': nan,\n","  'PascalBoxes_Precision/mAP@0.5IOU': 0.7333333333333334}\n","[12/22 14:13:52][INFO] ava_eval_helper.py: 171: AVA eval done in 0.013074 seconds.\n","[12/22 14:13:52][INFO] logging.py:  93: json_stats: {\"RAM\": \"3.65/12.72G\", \"_type\": \"val_epoch\", \"cur_epoch\": \"20\", \"gpu_mem\": \"2.57G\", \"map\": 0.73333, \"mode\": \"val\"}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jTxIuYrWHkkS"},"source":[""],"execution_count":null,"outputs":[]}]}